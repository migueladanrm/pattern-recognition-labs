{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AsignacionSemana6.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx6bGPStW3Fw"
      },
      "source": [
        "# Asignación de Semana 6\n",
        "*Introducción al Reconocimiento de Patrones* | **Miguel Rivas Méndez**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "En este documento se detalla la implementación de un modelo para el reconocimiento de dígitos manuscritos y la respuesta a las preguntas del capítulo 2: \"TensorFlow Basics and Training a Model\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fknfm0oqXN30"
      },
      "source": [
        "## 1. Modelo de reconocimiento de números manuscritos\n",
        "A continuación, se describe paso a paso la implementación del modelo de reconocimiento de números manuscritos.\n",
        "1. Importación de la librería TensorFlow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7u7km37wWxeE"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTnj2usaXl5E"
      },
      "source": [
        "2. Definición de las variables a utilizar para el entrenamiento y prueba del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWneVctmXuAv",
        "outputId": "986fa20e-20bc-4630-e01f-9a30ec39298c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "num_classes = 10\n",
        "img_rows, img_cols = 28, 28\n",
        "num_channels = 1\n",
        "input_shape = (img_rows, img_cols, num_channels)\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ7JJSGHX1eR"
      },
      "source": [
        "3. Se agregan capas de entrenamiento del modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LTV2pOoX7RZ"
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8q24vPtYAan"
      },
      "source": [
        "4. Se compila el modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CKBBHRARX757"
      },
      "source": [
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ng7Xq9IbYH0E"
      },
      "source": [
        "5. Se inicia el entrenamiento del modelo con **25** *epochs*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5vu2C8dYK-P",
        "outputId": "a83a66b0-dc5d-4a63-8619-649485052e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 874
        }
      },
      "source": [
        "model.fit(x_train, y_train, epochs=25, verbose=1, validation_data=(x_test, y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2187 - accuracy: 0.9393 - val_loss: 0.2052 - val_accuracy: 0.9412\n",
            "Epoch 2/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2023 - accuracy: 0.9440 - val_loss: 0.1913 - val_accuracy: 0.9453\n",
            "Epoch 3/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1887 - accuracy: 0.9472 - val_loss: 0.1809 - val_accuracy: 0.9473\n",
            "Epoch 4/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1769 - accuracy: 0.9511 - val_loss: 0.1717 - val_accuracy: 0.9507\n",
            "Epoch 5/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1666 - accuracy: 0.9538 - val_loss: 0.1636 - val_accuracy: 0.9516\n",
            "Epoch 6/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1572 - accuracy: 0.9567 - val_loss: 0.1539 - val_accuracy: 0.9554\n",
            "Epoch 7/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1492 - accuracy: 0.9585 - val_loss: 0.1466 - val_accuracy: 0.9572\n",
            "Epoch 8/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1416 - accuracy: 0.9607 - val_loss: 0.1418 - val_accuracy: 0.9597\n",
            "Epoch 9/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1352 - accuracy: 0.9626 - val_loss: 0.1372 - val_accuracy: 0.9601\n",
            "Epoch 10/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1290 - accuracy: 0.9646 - val_loss: 0.1326 - val_accuracy: 0.9620\n",
            "Epoch 11/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1235 - accuracy: 0.9662 - val_loss: 0.1268 - val_accuracy: 0.9638\n",
            "Epoch 12/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1184 - accuracy: 0.9676 - val_loss: 0.1230 - val_accuracy: 0.9645\n",
            "Epoch 13/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1136 - accuracy: 0.9684 - val_loss: 0.1196 - val_accuracy: 0.9666\n",
            "Epoch 14/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1094 - accuracy: 0.9700 - val_loss: 0.1161 - val_accuracy: 0.9672\n",
            "Epoch 15/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1053 - accuracy: 0.9712 - val_loss: 0.1137 - val_accuracy: 0.9669\n",
            "Epoch 16/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1015 - accuracy: 0.9723 - val_loss: 0.1116 - val_accuracy: 0.9685\n",
            "Epoch 17/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0981 - accuracy: 0.9731 - val_loss: 0.1080 - val_accuracy: 0.9696\n",
            "Epoch 18/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0949 - accuracy: 0.9742 - val_loss: 0.1063 - val_accuracy: 0.9695\n",
            "Epoch 19/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0917 - accuracy: 0.9753 - val_loss: 0.1045 - val_accuracy: 0.9703\n",
            "Epoch 20/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0890 - accuracy: 0.9756 - val_loss: 0.1018 - val_accuracy: 0.9701\n",
            "Epoch 21/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0862 - accuracy: 0.9766 - val_loss: 0.1008 - val_accuracy: 0.9706\n",
            "Epoch 22/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0836 - accuracy: 0.9776 - val_loss: 0.0975 - val_accuracy: 0.9715\n",
            "Epoch 23/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0812 - accuracy: 0.9779 - val_loss: 0.0967 - val_accuracy: 0.9717\n",
            "Epoch 24/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0791 - accuracy: 0.9787 - val_loss: 0.0947 - val_accuracy: 0.9725\n",
            "Epoch 25/25\n",
            "1875/1875 [==============================] - 3s 2ms/step - loss: 0.0767 - accuracy: 0.9792 - val_loss: 0.0933 - val_accuracy: 0.9722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f224a329fd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RoAvaQdvZyYV"
      },
      "source": [
        "De esta forma, tenemos un modelo que teóricamente reconoce números con un 97.92% de precisión."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0OpqO85bQBS"
      },
      "source": [
        "## 2.  Preguntas sobre TensorFlow\n",
        "En esta sección se da respuesta a las preguntas planteadas al final del capítulo 2.\n",
        "#### 1. ¿Qué es Keras en comparación a TensorFlow y cuál es su propósito?\n",
        "\n",
        "Keras se enfoca en brindar API's de alto nivel para entrenamiento de redes neuronales, por otra parte, TensorFlow corresponde tanto API's de alto como bajo nivel para tareas de aprendizaje automático.\n",
        "\n",
        "---\n",
        "\n",
        "#### 2. ¿Por qué TensorFlow usa grafos, y cómo se puede crear uno manualmente?\n",
        "La arquitectura de *TF* se basa en operaciones, las cuales se pueden representar como nodos que completan un grafo de dichas operaciones, esto facilita tareas como el uso en CPU's y GPU's por operaciones, o también, la ejecución en sistemas de cómputo distribuido. Además de esto, permite realizar optimizaciones de dicho grafo para evitar operaciones innecesarias.\n",
        "\n",
        "Los grafos se pueden implementar manualmente a través del módulo *AutoGraph*, concretamente, agregando el decorador `tf.function` a la función a implementar como tal grafo.\n",
        "\n",
        "---\n",
        "\n",
        "#### 3. ¿Cuál es la diferencia entre la ejecución \"ansiosa\" y la ejecución \"perezosa\"?\n",
        "La ejecución ansiosa, introducida en la versión 2 de TF, permite mostrar los resultados de una operación después de se ejecución, facilitando así la depuración, por ejemplo. Por otra parte, la ejecución perezosa, por otra parte, dará como resultado información de la operación realizada, pero no su resultado.\n",
        "\n",
        "---\n",
        "\n",
        "#### 4. ¿Cómo se pueden escribir registros en TensorBoard, y cómo se pueden mostrar?\n",
        "Para escribir registros con TensorBoard, se debe agregar el siguiente callback previo al entrenamiento del modelo.\n",
        "\n",
        "```python\n",
        "callbacks = [tf.keras.callbacks.TensorBoard('./logs_keras')]\n",
        "model.fit(x_train,y_train, epochs=5, verbose=1, validation_data=(x_test, y_test), callbacks=callbacks\n",
        "```\n",
        "Posteriormente, podemos ejecutar el siguiendo comando para mostrar los resultados:\n",
        "\n",
        "```\n",
        "tensorboard --logdir ./logs_keras\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "#### 5. ¿Cuáles son las principales diferencias entre TensorFlow versión 1 y 2?\n",
        "TensorFlow 2 añade una serie de características como la ejecución ansiosa, ya mencionada anteriormente. También AutoGraph para generar grafos a partir de código ansiosa, por otra parte añade mejor soporte para GPU's.\n",
        "\n",
        "---\n"
      ]
    }
  ]
}